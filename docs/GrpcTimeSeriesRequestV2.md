# GrpcTimeSeriesRequestV2

## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**end** | **datetime** | We specify query time ranges with a tuple of (end, duration, num_steps).  From these values, we compute:    - step_sec &#x3D; duration / num_steps    - start &#x3D; end - (step_sec * num_steps)  The returned timeseries will contain points between start and end that are evenly spaced at step_sec. More precisely, points[i] will correspond to the range: ((start + (step_sec * i)), (start + step_sec * (i + 1)].  We enforce the following constraints on all queries:    - end is expected to be in the UTC timezone    - end must be at or before the current time    - duration must be less than some MAX_QUERY_DURATION, currently 2 days    - duration must be an integral number of seconds    - duration / num_steps must result in an integral number of samples [1]    - duration / num_steps must be less than some MAX_NUM_SAMPLES    - num_steps must be less than MAX_NUM_POINTS (about 1000)  [1] We currently store data at 1sec, 30sec, and 600sec samples. So, when we derive step &#x3D; duration / num_steps, we enfore that step is either:    - integral if &lt; 30s as we read from the 1sec data, or    - a multiple of 30s if &gt; 30s and &lt; 600s as we read from the 30sec data,    - a multiple of 600s if &gt; 600s as we read from the 600sec data.  Queries that violate any of these constraints will result in an INVALID_ARGUMENT error. | [optional] 
**duration** | **str** |  | [optional] 
**num_steps** | **int** |  | [optional] 
**source_filters** | [**list[GrpcFilter]**](GrpcFilter.md) | Lists of filters for the source and destinations.  The &#x60;directionality&#x60;field determines how these labels get converted to labels queried against the backing TSDB.  For instance, if we query for    - source_filters &#x3D; [{&#39;role&#39;, IN [&#39;my-role&#39;]} and    - destination_filters &#x3D; [{&#39;az&#39;, IN, [&#39;my-az&#39;]}] Then they potentially get reversed with directionality:   - FORWARD, then these are executed as written.   - BACKWARD, then these become:       - source_filters &#x3D; [{&#39;az&#39;, IN, [&#39;my-az&#39;]}]       - destination_filters &#x3D; [{&#39;role&#39;, IN [&#39;my-role&#39;]}]   - BOTH, then both of the above queries are done and the results are        merged together. | [optional] 
**destination_filters** | [**list[GrpcFilter]**](GrpcFilter.md) |  | [optional] 
**metric** | **str** | Metric to return as timeseries.  If requesting a percent metric (such as drops), then the results are filtered to a min number of 200 drops per second as described in: timeseries/timeseries.go:getDropsCorrectedTimeSeries | [optional] 
**source_grouping** | **list[str]** | A list of labels that the returned timeseries will include.  If only one side of the groupings are specified, then the returned timeseries will be aggregated for that one side. E.g., if we specify a query for source_grouping &#x3D; [&#39;address&#39;], then the returned timeseries will be the sum of the specified metric aggregated by source address. If no grouping is specified, no cross-timeseries aggregation is performed.  Note: The response&#39;s &#x60;series.source_labels&#x60; and &#x60;series.destination_labels&#x60; will contain &#x60;source_grouping&#x60; and &#x60;destination_grouping&#x60;, for both FORWARD and REVERSED responses, i.e., reversed timeseries don&#39;t reverse the source and destination grouping labels. | [optional] 
**destination_grouping** | **list[str]** |  | [optional] 
**directionality** | [**GrpcDirectionality**](GrpcDirectionality.md) | Used to conditionally reverse the specified filters. | [optional] 
**locality** | [**GrpcLocality**](GrpcLocality.md) | / XXX(ekerzner) - Unclear what this is supposed to do. It likely doesn&#39;t / work. Will remove it before releasing v2 of this API. | [optional] 
**top_k** | **int** | Maximum number of time series to return. Defaults to 30 if unspecified. If set to -1, then we&#39;ll return all timeseries.  When requesting directionality FORWARD or REVERSE, then we will return no more than k timeseries. If requesting directionality BOTH, then we&#39;ll return at most 2*k timeseries, which include the k FORWARD timeseries and their corresponding REVERSE timeseries. | [optional] 
**min_total_values_threshold** | **float** | Threshold for corrected percent metrics: drops and *_percent.  For each point in the requested timeseries, if the rate of that point extrapolated into the entire time window is less than the specified threshold, then that point will be corrected to 0.  This is necessary for filtering outliers from connections that have sporadic patterns. For example, in one time step, a single packet dropped could mean a 20% drop rate. So, we use this threshold to filter such low traffic time steps.  XXX(ekerzner) - remove this before releasing v2 of this API. it never really worked right because it was inconsistent as we changed the requested step size.  Defaults to 0 (no filtering). | [optional] 
**no_rollups** | **bool** | Flag to manually disable the use of time-aggregated data.  Our default TSDB stores samples at 1sec resoltuion. Our \&quot;rolled up\&quot; TSDB stores data at 30sec resolution.  XXX(ekerzner) - This service was supposed to dynamically switch between 1s/30s data. But, it&#39;s unclear if this works or when it&#39;s enabled/disabled. We need to straighten this out before releasing v2 of the API. | [optional] 
**label_equality** | [**list[GrpcLabelEqualityPair]**](GrpcLabelEqualityPair.md) | Query structure to perform &#39;!&#x3D;&#39; or &#39;&#x3D;&#x3D;&#39; operations on a subset of timeseries labels.  We commonly use these to query for cross-zone traffic, which looks like { \&quot;label\&quot;: \&quot;az\&quot;, \&quot;equal\&quot;: false }. | [optional] 
**aggregation** | [**GrpcAggregationMethod**](GrpcAggregationMethod.md) | Describes how timeseries samples should be aggregated both over time and over groupings. The two options are: sum and mean.  We currently allow only one aggregation method for each metric. See: https://github.com/Flowmill/flowmill/blob/master/backend/timeseries_query/create_query.go#L183  XXX(ekerzner) - A consumer of our API doesn&#39;t care about the aggregation because they have no control over it. i.e., we require that they specify it, but there&#39;s only 1 valid aggregation method for each metric. We should remove this before releasing v2. | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)


